{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e65450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942eec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Set the path to your data \n",
    "DATA_FILE = \"text.txt\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "CHROMA_PATH = \"./my_chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4e6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Data ---\n",
    "loaders = TextLoader(DATA_FILE)\n",
    "data = loaders.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4905d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents with larger chunk size...\n",
      "File split into 3 chunks.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Optimize Splitting for Batching ---\n",
    "# Increase chunk size significantly. A 10,000-word file is about 60,000 characters.\n",
    "# By making the chunk size larger, you reduce the total number of documents (and API calls).\n",
    "# Using 4000 characters means approximately 25-30 documents are reduced to just 5-6 documents.\n",
    "# This cuts down connection overhead significantly.\n",
    "print(\"Splitting documents with larger chunk size...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000,           # set chunk size to 4000\n",
    "    chunk_overlap=200          # Added small overlap for context\n",
    ")\n",
    "splitter = text_splitter.split_documents(data) \n",
    "print(f\"File split into {len(splitter)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01270164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding model: nomic-embed-text\n",
      "Starting embedding process with Chroma...\n",
      "Embedding Complete!\n",
      "Total time taken: 6.58 seconds.\n",
      "Vector store saved to: ./my_chroma_db\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Embedding and Indexing ---\n",
    "print(f\"Initializing embedding model: {EMBEDDING_MODEL}\")\n",
    "embedding = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "# Start timer to measure the speed improvement\n",
    "start_time = time.time()\n",
    "\n",
    "# This single call will now make fewer, larger requests to Ollama\n",
    "print(\"Starting embedding process with Chroma...\")\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splitter, \n",
    "    embedding=embedding,\n",
    "    persist_directory=CHROMA_PATH\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Embedding Complete!\")\n",
    "print(f\"Total time taken: {elapsed_time:.2f} seconds.\")\n",
    "print(f\"Vector store saved to: {CHROMA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af05a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d49f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading vector files from local \n",
    "new_vector_db = Chroma(\n",
    "    persist_directory=\"my_ollama_chroma_index\",\n",
    "    embedding_function=embedding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5593dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d917c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d7b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac16de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444c0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8f5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59b734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a253849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
