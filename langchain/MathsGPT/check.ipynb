{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc911c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numexpr\n",
    "import streamlit as st\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.callbacks import StreamlitCallbackHandler\n",
    "from langchain_core.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bd5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluates a mathematical expression safely using numexpr. \n",
    "    Use this tool for all math-related questions.\"\"\"\n",
    "    try:\n",
    "        # Define allowed functions for security\n",
    "        local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
    "        result = numexpr.evaluate(\n",
    "            expression, global_dict={}, local_dict=local_dict\n",
    "        )\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Calculation Error: {e}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9706e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 09:05:18.946 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 09:05:18.947 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 09:05:19.032 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\Data_science\\Gen AI\\langchain_l\\venv\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-11-03 09:05:19.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 09:05:19.036 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -------setup  Streamlit UI -----\n",
    "st.set_page_config(page_title=\"LangChain: Text To Math Problem Solver And Data Search Assistant\", page_icon=\"ðŸ¦œ\")\n",
    "st.title(\"ðŸ¦œLangChain: Text To Math Problem Solver And Data Search Assistant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26aeaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 10:10:13.458 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 10:10:13.459 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 10:10:13.460 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 10:10:13.460 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 10:10:13.462 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 10:10:13.463 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 10:10:13.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Get the GROQ API Key and URL ---\n",
    "\n",
    "# Key is read as an empty string on first load\n",
    "groq_api_key1 = st.text_input(\"GROQ API key\", type=\"password\")\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# Load environment variables (like GROQ_API_KEY) from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d852f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 09:05:19.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 09:05:19.075 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 09:05:19.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 09:05:19.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if not groq_api_key:\n",
    "    st.info(\"Please add your GROQ API Key to be continue\")\n",
    "    st.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b3563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d13158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Pydantic input schema\n",
    "class WikipediaInput(BaseModel):\n",
    "    \"\"\"Input for the Wikipedia tool.\"\"\"\n",
    "    query: str = Field(description=\"The search query or topic to look up on Wikipedia.\")\n",
    "    \n",
    "## Initializing the tools\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia_tool = StructuredTool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia_wrapper.run,\n",
    "    description=\"A tool for search the internet to find the various information on the topics mentioned\",\n",
    "    args_schema=WikipediaInput\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19af0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **THIS MUST BE A SIMPLE STRING**\n",
    "SYSTEM_INSTRUCTIONS = \"You are a helpful assistant. Use the calculate tool for math and the wikipedia_tool for facts.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc463c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Add a checkpointer for state management (memory/history)\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ad2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tools into a single, flat list\n",
    "ALL_TOOLS = [calculate, wikipedia_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa63362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialization the Math tools\n",
    "agent_executor = create_agent(\n",
    "    model=llm, \n",
    "    tools=ALL_TOOLS, \n",
    "    system_prompt=SYSTEM_INSTRUCTIONS,\n",
    "    # Adding the checkpointer for persistent state/history\n",
    "    checkpointer=memory,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f2c588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Fixed Agent ---\n",
      "\n",
      "--- Final Answer ---\n",
      "The largest planet in the solar system is Jupiter.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Run the Agent ---\n",
    "print(\"--- Running Fixed Agent ---\")\n",
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the volume of a sphere with a radius of 5, using 4/3 * pi * r^3, and what is the largest planet?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"math-and-fact-query-fixed\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d3aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Prompt Template \n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Your agent tasked for solving user mathemetic  question. logically arrive at the solution  and provide detailed explanation and display it point wise for the question bellow.\"),\n",
    "        (\"user\", \"Question:{question}\")\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating chain\n",
    "chain = prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def reasoning_tool(question: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool for answering logic-based and reasoning questions. \n",
    "    Input should be the complete, logic-based question.\n",
    "    \"\"\"\n",
    "    # Use .invoke() for the modern LCEL chain instead of legacy .run()\n",
    "    return chain.invoke({\"question\": question}) \n",
    "    # NOTE: Adjust the input key (\"topic\") to match what your 'chain' expects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tools into a single, flat list\n",
    "ALL_TOOLS = [calculate, wikipedia_tool, reasoning_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53e8498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialization the Math tools\n",
    "agent_executor1 = create_agent(\n",
    "    model=llm, \n",
    "    tools=ALL_TOOLS, \n",
    "    system_prompt=SYSTEM_INSTRUCTIONS,\n",
    "    # Adding the checkpointer for persistent state/history\n",
    "    checkpointer=memory,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f01d2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Fixed Agent ---\n",
      "\n",
      "--- Final Answer ---\n",
      "So, 12 people will take 12 days to do the same work.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Run the Agent ---\n",
    "print(\"--- Running Fixed Agent ---\")\n",
    "response = agent_executor1.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"9 people can do a work in 16 days. How many days will 12 people take to do the same work? \")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"math-and-fact-query-fixed\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890aed44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafd208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f7126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9101dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d2b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321f3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7676b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c107a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
